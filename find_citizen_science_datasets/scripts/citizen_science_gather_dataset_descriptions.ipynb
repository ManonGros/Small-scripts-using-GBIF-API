{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import random\n",
    "import textblob\n",
    "from textblob.classifiers import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we predict if a dataset is part of a citizen science project?\n",
    "\n",
    "With the help of the [GBIF API](https://www.gbif.org/developer/summary) and textblob.\n",
    "\n",
    "See the documentation I used to write this  script:\n",
    "* https://www.analyticsvidhya.com/blog/2018/02/the-different-methods-deal-text-data-predictive-python/\n",
    "* https://stevenloria.com/simple-text-classification/\n",
    "\n",
    "## What do I label as citizen science in the training set?\n",
    "\n",
    "### What I label as \"citizen science\":\n",
    "* Metadata explicitly includes the words \"citizen\" or \"citizen science\" (or for the French version \"science\" or \"enquÃªte\" participative)\n",
    "* The metadata mentions that the dataset is partly or entirely made by volunteers\n",
    "* Bioblitz datasets\n",
    "\n",
    "### What I don't label as \"citizen science\":\n",
    "* What seems like compulsory student work\n",
    "* Personal collections or notebook (unless the description includes clue from above)\n",
    "\n",
    "## I - get the dataset's features to analyse from GBIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_set_of_words(dataset):\n",
    "    '''\n",
    "    Puts together titles, descriptions, methods and keywords\n",
    "    '''\n",
    "    set_of_words = dataset[\"title\"] + \" \"\n",
    "    if \"description\" in dataset:\n",
    "        set_of_words += dataset[\"description\"]+ \" \"\n",
    "    # Get keywords\n",
    "    if \"keywordCollections\" in dataset:\n",
    "        for kwcollection in dataset[\"keywordCollections\"]:\n",
    "            if \"keywords\" in kwcollection:\n",
    "                for kw in kwcollection[\"keywords\"]:\n",
    "                    set_of_words += str(kw)+ \" \"\n",
    "    # Get Methods\n",
    "    if \"samplingDescription\" in dataset:\n",
    "        for key in dataset[\"samplingDescription\"]:\n",
    "            if key != \"methodSteps\":\n",
    "                set_of_words += dataset[\"samplingDescription\"][key]+ \" \"\n",
    "            else:\n",
    "                for methodStep in dataset[\"samplingDescription\"][key]:\n",
    "                    set_of_words += str(methodStep)+ \" \"\n",
    "    return set_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(columns=[\"Description\", \"Language\"])\n",
    "\n",
    "# We are excluding datasets from organizations that generated the metadata automatically\n",
    "# PLAZI and PANGEA\n",
    "exclude = ['7ce8aef0-9e92-11dc-8738-b8a03c50a862',\n",
    "           'd5778510-eb28-11da-8629-b8a03c50a862']\n",
    "offset = 0\n",
    "step = 900\n",
    "end_of_records = False\n",
    "while not end_of_records:\n",
    "    param = {\n",
    "        \"offset\": offset,\n",
    "        \"limit\": step\n",
    "    }\n",
    "    # Query API\n",
    "    response = requests.get(\"http://api.gbif.org/v1/dataset\", param)\n",
    "    response = response.json()\n",
    "    offset += step\n",
    "    end_of_records = response[\"endOfRecords\"]\n",
    "    for dataset in response[\"results\"]:\n",
    "        # exclude dataset from PLAZI and PANGEA\n",
    "        if dataset[\"publishingOrganizationKey\"] not in exclude and dataset[\"type\"] != \"CHECKLIST\":\n",
    "            res.at[dataset[\"key\"], \"Language\"] = dataset[\"language\"]\n",
    "            # Get title, description, keywords, methods of the dataset\n",
    "            res.at[dataset[\"key\"], \"Description\"] = extract_set_of_words(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data to avoid rerunning everything, everytime I debug my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res.to_csv(\"../raw_descriptions.tsv\", index=True, sep=\"\\t\")\n",
    "\n",
    "res = pd.read_table(\"../raw_descriptions.tsv\")\n",
    "res = res.set_index(\"UUID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training  + testing sets: partially manually annotated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_table(\"../some_manually_annotated_datasets.tsv\")\n",
    "training_set = training_set.set_index(\"UUID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II - Set the parameters for data cleaning and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = \"Description\" # we want to find words in the description\n",
    "frequency_threshold = 15 # how many most frequent word do we remove\n",
    "rare_threshold_word_number = 2 # how many time a word should appear to be kept\n",
    "parameter_selection_training_set = 800 # Size of training set + selection of parameters\n",
    "crossValidation = 4\n",
    "triming_threshold_for_model = 15 # number of words we want to keep from model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III - Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove underscore\n",
    "res[feature] = res[feature].str.replace(\"_\", \" \")\n",
    "res[feature] = res[feature].str.replace(\"-\", \" \")\n",
    "\n",
    "# Set everything to lower case\n",
    "res[feature] = res[feature].apply(lambda x: \" \".join(x.lower() for x in x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the translation stopped working after an hour of using it. Apparently iy is a common issue with libraries using the google API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Translate sentence if needed\n",
    "# for dataset in res.index.tolist():\n",
    "#     if res.loc[dataset, \"Language\"] != \"eng\":\n",
    "#         print(dataset)\n",
    "#         res.at[dataset, feature] = str(textblob.TextBlob(res.loc[dataset, feature]).translate(to='en'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "res[feature] = res[feature].str.replace('[^\\w\\s]', '')\n",
    "res[feature] = res[feature].str.replace('[\\d]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most frequent words by language\n",
    "for language in list(set(res.Language.tolist())):\n",
    "    freq = pd.Series(' '.join(res[res.Language == language][feature]).split()).value_counts()[:frequency_threshold]\n",
    "    freq = list(freq.index)\n",
    "    # Remove the most frequent words\n",
    "    res[feature] = res[feature].apply(lambda x: \" \".join([c for c in x.split() if c not in freq]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace some key words\n",
    "words_to_replace = pd.read_table(\"../wd_replace.txt\")\n",
    "words_to_replace = words_to_replace.set_index(\"word\")\n",
    "for word in words_to_replace.index.tolist():\n",
    "    res[feature] = res[feature].str.replace(word, words_to_replace.loc[word, \"replacement\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find the rare words # OPTIONAL because it takes too much time\n",
    "# freq = pd.Series(' '.join(res[feature]).split()).value_counts()\n",
    "# freq = freq[freq < rare_threshold_word_number]\n",
    "# freq = list(freq.index)\n",
    "# # Remove rare words\n",
    "# res[feature] = res[feature].apply(lambda x: \" \".join([c for c in x.split() if c not in freq]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct spelling - not done here because it takes too much time\n",
    "# res[feature] = res[feature].apply(lambda x: str(textblob.TextBlob(x).correct()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization (remove some letters in words to make it more \"universal\")\n",
    "res[feature] = res[feature].apply(lambda x: \" \".join([textblob.Word(word).lemmatize() for word in x.split()]))\n",
    "\n",
    "# Remove as many NAs as possible\n",
    "res[feature] = res[feature].str.replace(\" na \", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set\n",
    "data_training_set = pd.concat([res, training_set], join=\"inner\", axis=1)\n",
    "\n",
    "# Reformat dataset\n",
    "index_list = data_training_set.index.tolist()\n",
    "random.shuffle(index_list)\n",
    "index_test_set = index_list[parameter_selection_training_set:len(index_list)]\n",
    "index_training_set = index_list[0:parameter_selection_training_set]\n",
    "\n",
    "data_training_set = data_training_set.loc[index_training_set]\n",
    "data_training_set = list(data_training_set[[feature, 'CS']].itertuples(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV - Train and test Classifier - Naive Bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classifier\n",
    "word_for_model = []\n",
    "\n",
    "for fold in range(0, crossValidation):\n",
    "    cl = NaiveBayesClassifier(data_training_set[fold:(fold+1)*int(len(data_training_set)/crossValidation)])\n",
    "    informative_feature = cl.informative_features(triming_threshold_for_model)\n",
    "    for word in informative_feature:\n",
    "        word_for_model.append(word[0].replace(\"contains(\",\"\").replace(\")\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F    788\n",
       "T    226\n",
       "Name: CS, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put back the performance in the context \n",
    "training_set[\"CS\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eng    6591\n",
       "spa    1757\n",
       "fra    1114\n",
       "por     223\n",
       "nor       6\n",
       "zho       6\n",
       "rus       2\n",
       "glg       1\n",
       "cat       1\n",
       "Name: Language, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Languages\n",
    "res[\"Language\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V - What word is associated with citizen science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "na              3\n",
       "select          3\n",
       "professional    3\n",
       "occurence       3\n",
       "school          3\n",
       "validated       3\n",
       "organised       2\n",
       "amateur         2\n",
       "dedicated       2\n",
       "spot            2\n",
       "you             2\n",
       "citizen         2\n",
       "hosted          2\n",
       "volunteer       2\n",
       "connaissance    1\n",
       "validation      1\n",
       "since           1\n",
       "object          1\n",
       "contribution    1\n",
       "order           1\n",
       "asked           1\n",
       "camp            1\n",
       "participant     1\n",
       "absence         1\n",
       "deposited       1\n",
       "search          1\n",
       "help            1\n",
       "submit          1\n",
       "monitor         1\n",
       "ensure          1\n",
       "imported        1\n",
       "late            1\n",
       "collated        1\n",
       "of              1\n",
       "watcher         1\n",
       "conduct         1\n",
       "thousand        1\n",
       "surroundings    1\n",
       "occurring       1\n",
       "bioblitz        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the most informative words\n",
    "keywords = pd.Series(word_for_model).value_counts()\n",
    "keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI - Train and test model on reduced set of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_set_of_words = keywords[keywords > 1].index.tolist()\n",
    "reduced_set_of_words += [\"herbarium\", \"museum\", \"inaturalist\"]\n",
    "reduced_set_of_words = set(reduced_set_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[feature] = res[feature].apply(lambda x: \" \".join([c for c in x.split() if c in reduced_set_of_words]))\n",
    "res[feature] = res[feature].str.replace(\" na \", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduced training set\n",
    "reduced_set = pd.concat([res, training_set], join=\"inner\", axis=1)\n",
    "\n",
    "# Reformat dataset\n",
    "reduced_training_set = reduced_set.loc[index_training_set]\n",
    "reduced_training_set = list(reduced_training_set[[feature, 'CS']].itertuples(index=False))\n",
    "\n",
    "test_set = reduced_set.loc[index_test_set]\n",
    "test_set = list(test_set[[feature, 'CS']].itertuples(index=False))\n",
    "\n",
    "# train dataset\n",
    "# cl = NaiveBayesClassifier(reduced_training_set)\n",
    "cl = textblob.classifiers.DecisionTreeClassifier(reduced_training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if contains(citizen) == False: \n",
      "  if contains(volunteer) == False: \n",
      "    if contains(organised) == False: \n",
      "      if contains(amateur) == False: return 'F'\n",
      "      if contains(amateur) == True: return 'T'\n",
      "    if contains(organised) == True: \n",
      "      if contains(na) == False: return 'T'\n",
      "      if contains(na) == True: return 'T'\n",
      "  if contains(volunteer) == True: return 'T'\n",
      "if contains(citizen) == True: return 'T'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cl.pseudocode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "truePositive = 0\n",
    "trueNegative = 0\n",
    "falsePositive = 0\n",
    "falseNegative = 0\n",
    "for test in test_set:\n",
    "    if test[1] == \"T\":\n",
    "        if cl.classify(test[0]) == \"T\":\n",
    "            truePositive += 1\n",
    "        else:\n",
    "            falsePositive += 1\n",
    "    else:\n",
    "        if cl.classify(test[0]) == \"T\":\n",
    "            falseNegative += 1\n",
    "        else:\n",
    "            trueNegative += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on testing set\n",
      "\n",
      "True positive:\t 9.859154929577464\n",
      "True negative:\t 85.21126760563381\n",
      "False positive:\t 4.929577464788732\n",
      "False negative:\t 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance on testing set\\n\")\n",
    "print(\"True positive:\\t\", truePositive*100/len(test_set))\n",
    "print(\"True negative:\\t\", trueNegative*100/len(test_set))\n",
    "print(\"False positive:\\t\", falsePositive*100/len(test_set))\n",
    "print(\"False negative:\\t\", falseNegative*100/len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9507042253521126"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy\")\n",
    "cl.accuracy(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F    121\n",
       "T     21\n",
       "Name: CS, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put back the performance in the context \n",
    "reduced_set.loc[index_test_set][\"CS\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the rest of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_check = pd.DataFrame([\"UUID\", \"CS\"])\n",
    "for test in res.index.tolist():\n",
    "    if test not in training_set.index.tolist():\n",
    "        to_check.at[test, \"CS\"] = cl.classify(res.at[test, feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_and_description = pd.read_table(\"../raw_occurrence_dataset_descriptions_and_titles.tsv\")\n",
    "title_and_description = title_and_description.set_index(\"UUID\")\n",
    "to_check_w_title = pd.concat([title_and_description, to_check], join = \"inner\", axis=1)\n",
    "to_check_w_title.sort_values([\"CS\"], ascending=False).to_csv(\"../test_model_subsample.tsv\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
